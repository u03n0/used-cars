{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37705, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>transmission</th>\n",
       "      <th>color</th>\n",
       "      <th>mileage</th>\n",
       "      <th>year</th>\n",
       "      <th>fuel</th>\n",
       "      <th>engine_capacity</th>\n",
       "      <th>body_type</th>\n",
       "      <th>has_warranty</th>\n",
       "      <th>drivetrain</th>\n",
       "      <th>price</th>\n",
       "      <th>age</th>\n",
       "      <th>miles_per_year</th>\n",
       "      <th>price_per_mile</th>\n",
       "      <th>price_per_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subaru</td>\n",
       "      <td>outback</td>\n",
       "      <td>automatic</td>\n",
       "      <td>silver</td>\n",
       "      <td>190000</td>\n",
       "      <td>2010</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>2.5</td>\n",
       "      <td>universal</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>10900.00</td>\n",
       "      <td>15</td>\n",
       "      <td>12666.666667</td>\n",
       "      <td>0.057368</td>\n",
       "      <td>726.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subaru</td>\n",
       "      <td>outback</td>\n",
       "      <td>automatic</td>\n",
       "      <td>blue</td>\n",
       "      <td>290000</td>\n",
       "      <td>2002</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>3.0</td>\n",
       "      <td>universal</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>23</td>\n",
       "      <td>12608.695652</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>217.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>subaru</td>\n",
       "      <td>forester</td>\n",
       "      <td>automatic</td>\n",
       "      <td>red</td>\n",
       "      <td>402000</td>\n",
       "      <td>2001</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>2.5</td>\n",
       "      <td>suv</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>2800.00</td>\n",
       "      <td>24</td>\n",
       "      <td>16750.000000</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>116.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>subaru</td>\n",
       "      <td>impreza</td>\n",
       "      <td>mechanical</td>\n",
       "      <td>blue</td>\n",
       "      <td>10000</td>\n",
       "      <td>1999</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>3.0</td>\n",
       "      <td>sedan</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>9999.00</td>\n",
       "      <td>26</td>\n",
       "      <td>384.615385</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>384.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subaru</td>\n",
       "      <td>legacy</td>\n",
       "      <td>automatic</td>\n",
       "      <td>black</td>\n",
       "      <td>280000</td>\n",
       "      <td>2001</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>2.5</td>\n",
       "      <td>universal</td>\n",
       "      <td>False</td>\n",
       "      <td>all</td>\n",
       "      <td>2134.11</td>\n",
       "      <td>24</td>\n",
       "      <td>11666.666667</td>\n",
       "      <td>0.007622</td>\n",
       "      <td>88.921250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     make     model transmission   color  mileage  year      fuel  \\\n",
       "0  subaru   outback    automatic  silver   190000  2010  gasoline   \n",
       "1  subaru   outback    automatic    blue   290000  2002  gasoline   \n",
       "2  subaru  forester    automatic     red   402000  2001  gasoline   \n",
       "3  subaru   impreza   mechanical    blue    10000  1999  gasoline   \n",
       "4  subaru    legacy    automatic   black   280000  2001  gasoline   \n",
       "\n",
       "   engine_capacity  body_type  has_warranty drivetrain     price  age  \\\n",
       "0              2.5  universal         False        all  10900.00   15   \n",
       "1              3.0  universal         False        all   5000.00   23   \n",
       "2              2.5        suv         False        all   2800.00   24   \n",
       "3              3.0      sedan         False        all   9999.00   26   \n",
       "4              2.5  universal         False        all   2134.11   24   \n",
       "\n",
       "   miles_per_year  price_per_mile  price_per_year  \n",
       "0    12666.666667        0.057368      726.666667  \n",
       "1    12608.695652        0.017241      217.391304  \n",
       "2    16750.000000        0.006965      116.666667  \n",
       "3      384.615385        0.999900      384.576923  \n",
       "4    11666.666667        0.007622       88.921250  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/interim/cars.csv\")\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['price', 'has_warranty'])\n",
    "y = df['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['mileage', 'year', 'engine_capacity', 'age', 'miles_per_year', 'price_per_mile', 'price_per_year']\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "\n",
    "categorical_features = ['make', 'model', 'transmission', 'color', 'fuel', 'body_type', 'drivetrain']\n",
    "categorical_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/u03n0/Workspace/used-cars/venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [1] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit the transformer only on the training data and transform both training and test sets\n",
    "X_train_processed = preprocessor.fit_transform(X_train)  # Fit and transform on training data\n",
    "X_test_processed = preprocessor.transform(X_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sparse matrix to a dense NumPy array\n",
    "X_train_processed_dense = X_train_processed.toarray()\n",
    "X_test_processed_dense = X_test_processed.toarray()\n",
    "\n",
    "# Now convert them to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_processed_dense, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_processed_dense, dtype=torch.float32)\n",
    "\n",
    "# Convert the target variable (price) to tensors\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 16952467.7336\n",
      "Epoch [2/100], Loss: 1958731.8232\n",
      "Epoch [3/100], Loss: 1601906.7483\n",
      "Epoch [4/100], Loss: 1479940.2123\n",
      "Epoch [5/100], Loss: 1415205.3867\n",
      "Epoch [6/100], Loss: 1371826.7989\n",
      "Epoch [7/100], Loss: 1333150.3392\n",
      "Epoch [8/100], Loss: 1310921.9692\n",
      "Epoch [9/100], Loss: 1278838.8410\n",
      "Epoch [10/100], Loss: 1252217.8271\n",
      "Epoch [11/100], Loss: 1228435.5757\n",
      "Epoch [12/100], Loss: 1216807.4246\n",
      "Epoch [13/100], Loss: 1193872.6348\n",
      "Epoch [14/100], Loss: 1180554.0407\n",
      "Epoch [15/100], Loss: 1162067.1552\n",
      "Epoch [16/100], Loss: 1151313.6325\n",
      "Epoch [17/100], Loss: 1139444.8581\n",
      "Epoch [18/100], Loss: 1136499.0320\n",
      "Epoch [19/100], Loss: 1117076.4129\n",
      "Epoch [20/100], Loss: 1102211.0709\n",
      "Epoch [21/100], Loss: 1097191.2551\n",
      "Epoch [22/100], Loss: 1086310.9441\n",
      "Epoch [23/100], Loss: 1082338.0659\n",
      "Epoch [24/100], Loss: 1065698.9899\n",
      "Epoch [25/100], Loss: 1058351.1552\n",
      "Epoch [26/100], Loss: 1055084.0806\n",
      "Epoch [27/100], Loss: 1051616.0150\n",
      "Epoch [28/100], Loss: 1039457.0566\n",
      "Epoch [29/100], Loss: 1032885.6803\n",
      "Epoch [30/100], Loss: 1029471.9844\n",
      "Epoch [31/100], Loss: 1013690.4289\n",
      "Epoch [32/100], Loss: 1012187.9723\n",
      "Epoch [33/100], Loss: 1006876.1557\n",
      "Epoch [34/100], Loss: 1003133.9140\n",
      "Epoch [35/100], Loss: 1001220.7491\n",
      "Epoch [36/100], Loss: 990664.0004\n",
      "Epoch [37/100], Loss: 986842.1666\n",
      "Epoch [38/100], Loss: 980443.6961\n",
      "Epoch [39/100], Loss: 979483.5501\n",
      "Epoch [40/100], Loss: 972883.6995\n",
      "Epoch [41/100], Loss: 964048.4261\n",
      "Epoch [42/100], Loss: 964579.9820\n",
      "Epoch [43/100], Loss: 959321.9575\n",
      "Epoch [44/100], Loss: 956149.4526\n",
      "Epoch [45/100], Loss: 949087.8656\n",
      "Epoch [46/100], Loss: 943735.9549\n",
      "Epoch [47/100], Loss: 943647.9470\n",
      "Epoch [48/100], Loss: 937429.5938\n",
      "Epoch [49/100], Loss: 933887.5422\n",
      "Epoch [50/100], Loss: 929966.4053\n",
      "Epoch [51/100], Loss: 923541.9823\n",
      "Epoch [52/100], Loss: 917856.8077\n",
      "Epoch [53/100], Loss: 906242.2156\n",
      "Epoch [54/100], Loss: 882720.0585\n",
      "Epoch [55/100], Loss: 861893.6654\n",
      "Epoch [56/100], Loss: 822337.6175\n",
      "Epoch [57/100], Loss: 787748.4670\n",
      "Epoch [58/100], Loss: 749199.2843\n",
      "Epoch [59/100], Loss: 719650.0683\n",
      "Epoch [60/100], Loss: 677921.6120\n",
      "Epoch [61/100], Loss: 645293.3188\n",
      "Epoch [62/100], Loss: 619097.0738\n",
      "Epoch [63/100], Loss: 577134.0122\n",
      "Epoch [64/100], Loss: 549471.8883\n",
      "Epoch [65/100], Loss: 512116.7702\n",
      "Epoch [66/100], Loss: 486373.8613\n",
      "Epoch [67/100], Loss: 450726.7960\n",
      "Epoch [68/100], Loss: 417975.9131\n",
      "Epoch [69/100], Loss: 375269.0911\n",
      "Epoch [70/100], Loss: 338910.2449\n",
      "Epoch [71/100], Loss: 312980.3627\n",
      "Epoch [72/100], Loss: 277571.9465\n",
      "Epoch [73/100], Loss: 248420.8052\n",
      "Epoch [74/100], Loss: 224558.5917\n",
      "Epoch [75/100], Loss: 201338.9387\n",
      "Epoch [76/100], Loss: 185127.4387\n",
      "Epoch [77/100], Loss: 167484.8119\n",
      "Epoch [78/100], Loss: 159650.8087\n",
      "Epoch [79/100], Loss: 139886.9005\n",
      "Epoch [80/100], Loss: 143323.9455\n",
      "Epoch [81/100], Loss: 123013.8781\n",
      "Epoch [82/100], Loss: 128787.4510\n",
      "Epoch [83/100], Loss: 118257.4752\n",
      "Epoch [84/100], Loss: 110346.8102\n",
      "Epoch [85/100], Loss: 110805.4019\n",
      "Epoch [86/100], Loss: 104374.1251\n",
      "Epoch [87/100], Loss: 97899.4407\n",
      "Epoch [88/100], Loss: 96630.6360\n",
      "Epoch [89/100], Loss: 93119.3499\n",
      "Epoch [90/100], Loss: 88563.8795\n",
      "Epoch [91/100], Loss: 82056.1174\n",
      "Epoch [92/100], Loss: 82436.2872\n",
      "Epoch [93/100], Loss: 78536.2907\n",
      "Epoch [94/100], Loss: 80433.8990\n",
      "Epoch [95/100], Loss: 77326.6478\n",
      "Epoch [96/100], Loss: 75668.2003\n",
      "Epoch [97/100], Loss: 71615.0956\n",
      "Epoch [98/100], Loss: 70192.9062\n",
      "Epoch [99/100], Loss: 70431.1689\n",
      "Epoch [100/100], Loss: 67945.3179\n",
      "Test Loss: 207538.9541, MAE: 193.8604\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Check if CUDA is available, if yes, use it, else fallback to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Neural Network Model (DNN/MLP)\n",
    "class CarPricePredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(CarPricePredictor, self).__init__()\n",
    "        # Defining layers: More layers and neurons can be added\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # Input layer -> hidden layer 1\n",
    "        self.fc2 = nn.Linear(128, 64)         # Hidden layer 1 -> hidden layer 2\n",
    "        self.fc3 = nn.Linear(64, 32)          # Hidden layer 2 -> hidden layer 3\n",
    "        self.fc4 = nn.Linear(32, 1)           # Hidden layer 3 -> output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass data through layers with ReLU activation\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)  # Output layer, no activation (regression task)\n",
    "        return x\n",
    "\n",
    "# Initialize the model and move it to the device (GPU or CPU)\n",
    "input_dim = X_train_tensor.shape[1]  # Number of features after preprocessing\n",
    "model = CarPricePredictor(input_dim).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move data to GPU (if available)\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "# DataLoader for batching\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        # Move data to the device (GPU or CPU)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "# Evaluation on test data\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    test_loss = 0.0\n",
    "    test_preds = []\n",
    "    test_true = []\n",
    "    for inputs, labels in test_loader:\n",
    "        # Move data to the device (GPU or CPU)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Collect predictions and true values for evaluation\n",
    "        test_preds.append(outputs.cpu().numpy())\n",
    "        test_true.append(labels.cpu().numpy())\n",
    "\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_preds = np.concatenate(test_preds)\n",
    "    test_true = np.concatenate(test_true)\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE)\n",
    "    mae = mean_absolute_error(test_true, test_preds)\n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, MAE: {mae:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
